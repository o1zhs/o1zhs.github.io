<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 基于机器学习的物理不可克隆函数(PUF)建模攻击 · Abigale</title><meta name="description" content="基于机器学习的物理不可克隆函数(PUF)建模攻击 - zhs"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Abigale"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://www.abigale.xin" target="_blank" class="nav-list-link">ALIYUN</a></li><li class="nav-list-item"><a href="https://github.com/o1zhs" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">基于机器学习的物理不可克隆函数(PUF)建模攻击</h1><div class="post-info">Apr 26, 2018</div><div class="post-content"><h2 id="一、机器学习"><a href="#一、机器学习" class="headerlink" title="一、机器学习"></a>一、机器学习</h2><p>​    第一次接触机器学习，这个实验在做的过程中相当痛苦。在实验刚开始的很长一段时间内都没有建模的思路，而且机器学习也从来没有接触过。但是最后参考我们学校研究生学长的思路，还是将实验做出了最终正确的结果。</p>
<p>​    什么是机器学习？</p>
<p>​    1+1等于几 ?<br>    50<br>    笨，多了</p>
<p>​    1+2 等于几?<br>    20<br>    笨，多了</p>
<p>​    3+4 等于几?<br>    7<br>    真聪明，对了</p>
<p>​    6+9 等于几?<br>    13<br>    笨，少了</p>
<p>​    久而久之……</p>
<p>​    2+2 等于几? 4</p>
<p>​    4+5 等于几? 9</p>
<p>​    这就是机器学习，准确来说是最常见的一种，监督学习。最开始的几步是对于模型的训练，“多了”或“少了”可以理解为训练时的误差，模型根据误差调整自身参数，这就是机器学习里常用的反向传播(Backpropagation)的简单的解释。</p>
<p>​    在传统的利用计算机解决问题的途径中，我们通常是给定一个输入，通过施加一定的条件（或算法），最终得到一个输出结果。这也就是把通常的生活问题转化成一个计算问题，通过设计算法，来解决问题。如下图：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqps6pwlskj30k808s768.jpg" alt=""></p>
<p>​    但是有一类问题，人类是找不到这样的模式，来解决问题的。以 OCR 字符识别为例，输入是手写体(数字)图片，输出是 0-9 字符串，我们并不知道怎么把输入转换成输出，因为手写体因人而异，随机性很大。</p>
<p>​    换句话说，这个时候，我们缺的是知识(如何映射)，不过幸运的是，我们有(实例)数据。</p>
<p>​    而把这个知识通过机器(计算机)学出来的过程，叫做机器学习。这个学出来的知识(或经验)，可以用于新的输入，产生新的输出。如下图：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqps7nf79bj30jp0bon25.jpg" alt=""></p>
<h2 id="二、PUF以及建模攻击分析"><a href="#二、PUF以及建模攻击分析" class="headerlink" title="二、PUF以及建模攻击分析"></a>二、PUF以及建模攻击分析</h2><p>​    物理不可克隆函数(Physical Unclonable Function，PUF)是一种新的轻量级硬件安全原语。当输入一个激励时，PUF 利用芯片制造过程中难以预测的工艺偏差(Process Variation)，输出依赖于芯片的不可克隆的响应，非常适合资源受限环境下的设备认证。然而，攻击者可以收集一定数量的激励响应对将 PUF 进行建模，因此，PUF 易受基于机器学习建模攻击。下图是一种典型的PUF——Arbiter PUF，其中{C1,C2,…,Cn-1,Cn}共同组成激励，r为响应。其原理是:一个脉冲信号 T 会在Arbiter PUF 上下两条路径同时传播，通过激励{C1,C2,…,Cn-1,Cn}改变路径(如 C1=1 时，在 M1 阶段交叉传播;C1=0 时，在 M1 阶段平行传播)，由于工艺偏差会影响不同路径的传播快慢，最终导致上下两条路径信号传播产生快慢差异，比较传播快慢生成激励响应r(0 或 1)。结构的示意图如下：            </p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fqpsix5lplj30l4089401.jpg" alt=""></p>
<p>​    我们假定示意图中的n为64，也就是我们组成激励为64位。下面我们来分析一下这个结构。一共64位的激励输入，也就是2^64种激励组合，在加上的最后一位的输出，组成了我们的数据集。</p>
<p>​    但是如果只把64位的01串和最后的一位01输出当做建模的结果的话，放进机器学习的算法中进行训练的话，不管数据集有多大，最后的测试结果正确率只能有50%左右，因为这样屏蔽了PUF内部的工作结构。因此我们的建模方式必须要考虑PUF内部的工作结构，能够把电流传播的路径考虑进去。</p>
<h2 id="三、逻辑回归与SVM"><a href="#三、逻辑回归与SVM" class="headerlink" title="三、逻辑回归与SVM"></a>三、逻辑回归与SVM</h2><p>​    逻辑回归是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）回归模型中，y是一个定性变量，比如y=0或1，logistic方法主要应用于研究某些事件发生的概率。</p>
<p>​    SVM（Support Vector Machines）——支持向量机是在所有知名的数据挖掘算法中最健壮，最准确的方法之一，它属于二分类算法，可以支持线性和非线性的分类。</p>
<p>参考：</p>
<p><a href="https://blog.csdn.net/chibangyuxun/article/details/53148005" target="_blank" rel="noopener">https://blog.csdn.net/chibangyuxun/article/details/53148005</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/28860065" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/28860065</a></p>
<h2 id="四、PUF建模"><a href="#四、PUF建模" class="headerlink" title="四、PUF建模"></a>四、PUF建模</h2><p>​    我们知道逻辑回归的公式是:</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqpt92snn0j30ki01jdfv.jpg" alt=""></p>
<p>​    相对于线性回归，它在多了 sigmoid 函数(上图公式中的 g()函数)，g()的作用是使得 Y 的值保持在 0 到 1 之间，其表达式如下:</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fqpvaqtl2uj30l401rglm.jpg" alt=""></p>
<p>​    我们拥有简单的逻辑回归公式，是不是简单的将 Arbiter PUF 的输入激励当做逻辑回归的输入{x1,x2,…,xn }就行了呢?显然是不行的。</p>
<p>​    我们建模要符合 Arbiter PUF 实际的工作原理。举如下例子:</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fqpve047zrj30o20ahdh1.jpg" alt=""></p>
<p>​    如图，这是一个简单 4 阶 Arbiter PUF 对应激励(1011)的路径图，我们产生一位响应，只需要比较蓝红两条路径的信号传播快慢就行了。我们设逻辑回归的参数为{w0,w1,w2,w3,w4}，如果以(1011)作为输入，得到的结果为 w0+w1+w3+w4显然没有任何意义。</p>
<p>​    这时就需要变通了，我们需要在输入或者设参数上做点手脚来遵循 Arbiter-PUF 的工作原理。这里对 Arbiter PUF 的所有延迟段进行设参数。图中的(w11,w12,w13,w14)对应之前图中的(p,s,t,q)，这时我们产生响应相当于比较(w12+w24+w33+w42)和(w13+w21+w32+w43)的大小。即判断以下两个矩阵对应位置相乘后求和的正负。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqpvn0q51xj30lv0380t1.jpg" alt=""></p>
<p>​    可见激励(1011)和矩阵 C 是一一对应的，我们只需要对激励进行扩展就能完成建模。注意这里的矩阵相乘不是线性代数中的矩阵相乘，而是对应位置的数相乘。其实只要把矩阵做一下转置就可以对应线性代数中的矩阵相乘了。最终，我们把C矩阵编程一个1*256的矩阵，即把每行拼接起来，在编程进行计算做最后的一位01输出，我们的数据集手机方式就得以实现了。由于SVM算法的特性，我们需要把最后输出的0改为-1，以更方便来计算。</p>
<p>​    下面是各个路径对应的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">194.606</span>, <span class="number">195.394</span>, <span class="number">196.01</span>, <span class="number">195.874</span>, <span class="number">194.794</span>, <span class="number">193.683</span>, <span class="number">192.148</span>, <span class="number">195.4</span>, <span class="number">194.362</span>, <span class="number">193.634</span>, <span class="number">195.452</span>, <span class="number">192.461</span>, <span class="number">194.52</span>,</span><br><span class="line">        <span class="number">194.18</span>, <span class="number">194.802</span>, <span class="number">192.773</span>, <span class="number">194.291</span>, <span class="number">195.502</span>, <span class="number">195.698</span>, <span class="number">193.55</span>, <span class="number">196.461</span>, <span class="number">193.983</span>, <span class="number">196.106</span>, <span class="number">195.993</span>, <span class="number">195.995</span>,</span><br><span class="line">        <span class="number">195.289</span>, <span class="number">194.944</span>, <span class="number">194.071</span>, <span class="number">196.365</span>, <span class="number">194.347</span>, <span class="number">194.936</span>, <span class="number">194.951</span>, <span class="number">196.044</span>, <span class="number">194.796</span>, <span class="number">195.777</span>, <span class="number">193.982</span>, <span class="number">196.579</span>,</span><br><span class="line">        <span class="number">194.747</span>, <span class="number">196.359</span>, <span class="number">194.955</span>, <span class="number">196.574</span>, <span class="number">194.404</span>, <span class="number">194.944</span>, <span class="number">193.574</span>, <span class="number">195.21</span>, <span class="number">195.17</span>, <span class="number">193.35</span>, <span class="number">193.762</span>, <span class="number">193.704</span>, <span class="number">195.66</span>,</span><br><span class="line">        <span class="number">194.801</span>, <span class="number">195.984</span>, <span class="number">195.22</span>, <span class="number">195.836</span>, <span class="number">195.341</span>, <span class="number">195.87</span>, <span class="number">196.222</span>, <span class="number">196.488</span>, <span class="number">194.434</span>, <span class="number">193.008</span>, <span class="number">194.658</span>, <span class="number">196.154</span>,</span><br><span class="line">        <span class="number">194.116</span>, <span class="number">192.048</span>,</span><br><span class="line">        <span class="number">194.615</span>, <span class="number">195.435</span>, <span class="number">196.026</span>, <span class="number">195.86</span>, <span class="number">194.767</span>, <span class="number">193.7</span>, <span class="number">192.157</span>, <span class="number">195.408</span>, <span class="number">194.414</span>, <span class="number">193.562</span>, <span class="number">195.477</span>, <span class="number">192.475</span>,</span><br><span class="line">        <span class="number">194.526</span>, <span class="number">194.178</span>, <span class="number">194.732</span>, <span class="number">192.583</span>, <span class="number">194.308</span>, <span class="number">195.519</span>, <span class="number">195.74</span>, <span class="number">193.585</span>, <span class="number">196.455</span>, <span class="number">194.032</span>, <span class="number">196.068</span>, <span class="number">196.012</span>,</span><br><span class="line">        <span class="number">196.055</span>, <span class="number">195.308</span>, <span class="number">194.953</span>, <span class="number">194.048</span>, <span class="number">196.423</span>, <span class="number">194.362</span>, <span class="number">194.977</span>, <span class="number">194.975</span>, <span class="number">196.081</span>, <span class="number">194.846</span>, <span class="number">195.799</span>, <span class="number">193.943</span>,</span><br><span class="line">        <span class="number">196.653</span>, <span class="number">194.844</span>, <span class="number">196.344</span>, <span class="number">195.02</span>, <span class="number">196.567</span>, <span class="number">194.385</span>, <span class="number">195.002</span>, <span class="number">193.54</span>, <span class="number">195.605</span>, <span class="number">195.719</span>, <span class="number">193.845</span>, <span class="number">193.85</span>,</span><br><span class="line">        <span class="number">193.702</span>, <span class="number">195.78</span>, <span class="number">194.8</span>, <span class="number">195.994</span>, <span class="number">195.06</span>, <span class="number">195.775</span>, <span class="number">195.308</span>, <span class="number">195.85</span>, <span class="number">196.388</span>, <span class="number">196.52</span>, <span class="number">194.348</span>, <span class="number">192.991</span>, <span class="number">194.688</span>,</span><br><span class="line">        <span class="number">196.296</span>, <span class="number">194.132</span>, <span class="number">192.139</span>,</span><br><span class="line">        <span class="number">194.643</span>, <span class="number">195.384</span>, <span class="number">195.969</span>, <span class="number">195.894</span>, <span class="number">194.776</span>, <span class="number">193.682</span>, <span class="number">192.129</span>, <span class="number">195.555</span>, <span class="number">194.426</span>, <span class="number">193.58</span>, <span class="number">195.446</span>, <span class="number">192.459</span>,</span><br><span class="line">        <span class="number">194.55</span>, <span class="number">194.2</span>, <span class="number">194.764</span>, <span class="number">192.783</span>, <span class="number">194.282</span>, <span class="number">195.54</span>, <span class="number">195.736</span>, <span class="number">193.621</span>, <span class="number">196.422</span>, <span class="number">194.011</span>, <span class="number">196.165</span>, <span class="number">195.98</span>, <span class="number">196.046</span>,</span><br><span class="line">        <span class="number">195.371</span>, <span class="number">194.909</span>, <span class="number">194.053</span>, <span class="number">196.373</span>, <span class="number">194.323</span>, <span class="number">194.997</span>, <span class="number">194.996</span>, <span class="number">196.169</span>, <span class="number">194.818</span>, <span class="number">195.829</span>, <span class="number">193.953</span>, <span class="number">196.678</span>,</span><br><span class="line">        <span class="number">194.829</span>, <span class="number">196.411</span>, <span class="number">195.006</span>, <span class="number">196.552</span>, <span class="number">194.398</span>, <span class="number">194.999</span>, <span class="number">193.572</span>, <span class="number">195.651</span>, <span class="number">195.73</span>, <span class="number">193.907</span>, <span class="number">193.793</span>, <span class="number">193.698</span>,</span><br><span class="line">        <span class="number">195.06</span>, <span class="number">194.838</span>, <span class="number">195.955</span>, <span class="number">195.053</span>, <span class="number">195.746</span>, <span class="number">195.359</span>, <span class="number">195.877</span>, <span class="number">196.354</span>, <span class="number">196.494</span>, <span class="number">194.449</span>, <span class="number">192.957</span>, <span class="number">194.704</span>,</span><br><span class="line">        <span class="number">196.18</span>, <span class="number">194.108</span>, <span class="number">192.211</span>,</span><br><span class="line">        <span class="number">194.558</span>, <span class="number">195.428</span>, <span class="number">196.014</span>, <span class="number">195.846</span>, <span class="number">194.833</span>, <span class="number">193.671</span>, <span class="number">192.1</span>, <span class="number">195.536</span>, <span class="number">194.341</span>, <span class="number">193.519</span>, <span class="number">195.585</span>, <span class="number">192.485</span>,</span><br><span class="line">        <span class="number">194.518</span>, <span class="number">194.184</span>, <span class="number">194.829</span>, <span class="number">192.84</span>, <span class="number">194.295</span>, <span class="number">195.572</span>, <span class="number">195.657</span>, <span class="number">193.571</span>, <span class="number">196.464</span>, <span class="number">194.05</span>, <span class="number">196.063</span>, <span class="number">195.891</span>,</span><br><span class="line">        <span class="number">196.012</span>, <span class="number">195.263</span>, <span class="number">194.978</span>, <span class="number">194.096</span>, <span class="number">196.328</span>, <span class="number">194.362</span>, <span class="number">194.92</span>, <span class="number">194.847</span>, <span class="number">196.08</span>, <span class="number">194.816</span>, <span class="number">195.736</span>, <span class="number">194.011</span>,</span><br><span class="line">        <span class="number">196.631</span>, <span class="number">194.738</span>, <span class="number">196.345</span>, <span class="number">194.996</span>, <span class="number">196.57</span>, <span class="number">194.413</span>, <span class="number">194.859</span>, <span class="number">193.54</span>, <span class="number">195.33</span>, <span class="number">195.24</span>, <span class="number">193.17</span>, <span class="number">193.733</span>, <span class="number">193.693</span>,</span><br><span class="line">        <span class="number">195.63</span>, <span class="number">194.807</span>, <span class="number">195.945</span>, <span class="number">195.65</span>, <span class="number">195.797</span>, <span class="number">195.355</span>, <span class="number">195.846</span>, <span class="number">196.234</span>, <span class="number">196.473</span>, <span class="number">194.456</span>, <span class="number">192.946</span>, <span class="number">194.744</span>,</span><br><span class="line">        <span class="number">196.188</span>, <span class="number">194.09</span>, <span class="number">192.009</span>]</span><br></pre></td></tr></table></figure>
<p>​    在实现过程中我们把数据导入到了csv文件中，并且把建模出来的数据导出到另外的csv文件中。</p>
<h2 id="五、逻辑回归建模攻击代码实现"><a href="#五、逻辑回归建模攻击代码实现" class="headerlink" title="五、逻辑回归建模攻击代码实现"></a>五、逻辑回归建模攻击代码实现</h2><h3 id="数据收集实现："><a href="#数据收集实现：" class="headerlink" title="数据收集实现："></a>数据收集实现：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shape</span><span class="params">(M)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> len(M), len(M[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">out1 = open(<span class="string">'traindatasetin.csv'</span>,<span class="string">'w'</span>)</span><br><span class="line">out2 = open(<span class="string">'traindatasetout.csv'</span>,<span class="string">'w'</span>)</span><br><span class="line">csv_writer1 = csv.writer(out1)</span><br><span class="line">csv_writer2 = csv.writer(out2)</span><br><span class="line">csv_file = csv.reader(open(<span class="string">'仿真Arbiter_PUF.csv'</span>,<span class="string">'r'</span>))</span><br><span class="line"></span><br><span class="line">PUFdelay_np = []</span><br><span class="line">PUFdelay = []</span><br><span class="line">delay1 = <span class="number">0</span></span><br><span class="line">delay2 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> csv_file:</span><br><span class="line">    PUFdelay.append(i)</span><br><span class="line"></span><br><span class="line">PUFdelay_np = np.array(PUFdelay, dtype=float)</span><br><span class="line"></span><br><span class="line">C_np = [([<span class="number">0</span>] * <span class="number">64</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]</span><br><span class="line">C_np_csv = []</span><br><span class="line">seed = <span class="string">"01"</span></span><br><span class="line">counter1 = <span class="number">0</span></span><br><span class="line"><span class="comment">#counter0 = 0</span></span><br><span class="line">counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> counter != <span class="number">2000</span>:</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">64</span>):</span><br><span class="line">		binary = random.choice(seed)</span><br><span class="line">		<span class="keyword">if</span> binary == <span class="string">"1"</span>:</span><br><span class="line">			delaymiddle = delay2</span><br><span class="line">			delay2 = delay1</span><br><span class="line">			delay1 = delaymiddle</span><br><span class="line">			delay1 += float(PUFdelay[<span class="number">1</span>][i])</span><br><span class="line">			delay2 += float(PUFdelay[<span class="number">2</span>][i])</span><br><span class="line">			C_np[<span class="number">0</span>][i] = <span class="number">0</span></span><br><span class="line">			C_np[<span class="number">3</span>][i] = <span class="number">0</span></span><br><span class="line">			counter1 += <span class="number">1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">1</span>][i] = <span class="number">1</span></span><br><span class="line">				C_np[<span class="number">2</span>][i] = <span class="number">-1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">1</span>][i] = <span class="number">-1</span></span><br><span class="line">				C_np[<span class="number">2</span>][i] = <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> binary == <span class="string">"0"</span>:</span><br><span class="line">			delay1 += float(PUFdelay[<span class="number">0</span>][i])</span><br><span class="line">			delay2 += float(PUFdelay[<span class="number">3</span>][i])</span><br><span class="line">			C_np[<span class="number">1</span>][i] = <span class="number">0</span></span><br><span class="line">			C_np[<span class="number">2</span>][i] = <span class="number">0</span></span><br><span class="line">			<span class="comment">#counter0 += 1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">0</span>][i] = <span class="number">-1</span></span><br><span class="line">				C_np[<span class="number">3</span>][i] = <span class="number">1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">0</span>][i] = <span class="number">1</span></span><br><span class="line">				C_np[<span class="number">3</span>][i] = <span class="number">-1</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">64</span>):</span><br><span class="line">			C_np_csv.append(C_np[i][j])</span><br><span class="line">	csv_writer1.writerow(C_np_csv)</span><br><span class="line">	<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">if</span>(delay1 &gt; delay2):</span><br><span class="line">			csv_writer2.writerow(<span class="string">"1"</span>)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			csv_writer2.writerow(<span class="string">"0"</span>)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">if</span>(delay1 &lt;= delay2):</span><br><span class="line">			csv_writer2.writerow(<span class="string">"1"</span>)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			csv_writer2.writerow(<span class="string">"0"</span>)</span><br><span class="line">	counter1 = <span class="number">0</span></span><br><span class="line">	delay1 = <span class="number">0</span></span><br><span class="line">	delay2 = <span class="number">0</span></span><br><span class="line">	C_np_csv = []</span><br><span class="line">	counter += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="逻辑回归建模攻击实现："><a href="#逻辑回归建模攻击实现：" class="headerlink" title="逻辑回归建模攻击实现："></a>逻辑回归建模攻击实现：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#tensorflow 实现 Logistic Regression</span></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">x_test = pd.read_csv(<span class="string">"testdatasetin.csv"</span>, header=<span class="keyword">None</span>)  <span class="comment"># 测试集特征</span></span><br><span class="line">x_train = pd.read_csv(<span class="string">"traindatasetin.csv"</span>, header=<span class="keyword">None</span>)  <span class="comment"># 训练集特征</span></span><br><span class="line">y_train = pd.read_csv(<span class="string">"traindatasetout.csv"</span>, header=<span class="keyword">None</span>)  <span class="comment"># 训练集标签</span></span><br><span class="line">y_test = pd.read_csv(<span class="string">"testdatasetout.csv"</span>, header=<span class="keyword">None</span>)  <span class="comment"># 测试集标签</span></span><br><span class="line"></span><br><span class="line">y_train = tf.concat([<span class="number">1</span> - y_train, y_train], <span class="number">1</span>)</span><br><span class="line">y_test = tf.concat([<span class="number">1</span> - y_test, y_test], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数定义</span></span><br><span class="line">learning_rate = <span class="number">0.05</span>  <span class="comment"># 学习率</span></span><br><span class="line">training_epochs = <span class="number">300</span>  <span class="comment"># 训练迭代次数</span></span><br><span class="line">batch_size = <span class="number">100</span>  <span class="comment"># 分页的每页大小（后面训练采用了批量处理的方法）</span></span><br><span class="line">display_step = <span class="number">15</span>  <span class="comment"># 何时打印到屏幕的参量</span></span><br><span class="line"></span><br><span class="line">n_samples = x_train.shape[<span class="number">0</span>]  <span class="comment"># sample_num 训练样本数量</span></span><br><span class="line">n_features = x_train.shape[<span class="number">1</span>]  <span class="comment"># feature_num 特征数量 256</span></span><br><span class="line">n_class = <span class="number">2</span></span><br><span class="line"><span class="comment">#变量定义</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_features])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_class])</span><br><span class="line"><span class="comment">#权重定义</span></span><br><span class="line">W = tf.Variable(tf.zeros([n_features, n_class]), name=<span class="string">"weight"</span>)</span><br><span class="line">b = tf.Variable(tf.zeros([n_class]), name=<span class="string">"bias"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#y=x*w+b 线性</span></span><br><span class="line">pred = tf.matmul(x, W) + b</span><br><span class="line"></span><br><span class="line"><span class="comment">#准确率</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失</span></span><br><span class="line">cost = tf.reduce_sum(</span><br><span class="line">    tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">train_accuracy = []</span><br><span class="line">test_accuracy = []</span><br><span class="line">avg_cost = []</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">            <span class="comment">#avg_cost = 0</span></span><br><span class="line">            total_batch = int(n_samples / batch_size)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">                _, c = sess.run([optimizer, cost],</span><br><span class="line">                                feed_dict=&#123;x: x_train[i * batch_size: (i + <span class="number">1</span>) * batch_size],</span><br><span class="line">                                           y: y_train[i * batch_size: (i + <span class="number">1</span>) * batch_size, :].eval()&#125;)</span><br><span class="line"></span><br><span class="line">                train_accuracy.append(accuracy.eval(</span><br><span class="line">                    &#123;x: x_train, y: y_train.eval()&#125;))</span><br><span class="line">                <span class="comment">#ax2.plot(epoch+1, avg_cost, 'c.')</span></span><br><span class="line">                test_accuracy.append(accuracy.eval(</span><br><span class="line">                    &#123;x: x_test, y: y_test.eval()&#125;))</span><br><span class="line">                avg_cost.append(c / total_batch)</span><br><span class="line">            <span class="comment">#plt.plot(epoch + 1, avg_cost, 'co')</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Epoch:"</span>, <span class="string">"%04d"</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, c/total_batch)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line">        print(<span class="string">"Testing Accuracy:"</span>, accuracy.eval(</span><br><span class="line">            &#123;x: x_test, y: y_test.eval()&#125;))</span><br><span class="line"></span><br><span class="line">        plt.suptitle(<span class="string">"learning rate=%f  training epochs=%i  sample_num=%i"</span> % (</span><br><span class="line">            learning_rate, training_epochs, n_samples), size=<span class="number">14</span>)</span><br><span class="line">        plt.plot(avg_cost)</span><br><span class="line">        plt.plot(train_accuracy)</span><br><span class="line">        plt.plot(test_accuracy)</span><br><span class="line">        plt.legend([<span class="string">'loss'</span>, <span class="string">'train_accuracy'</span>, <span class="string">'test_accuracy'</span>])</span><br><span class="line">        plt.ylim(<span class="number">0.</span>, <span class="number">1.5</span>)</span><br><span class="line">        <span class="comment">#plt.savefig('AC8.png', dpi=300)</span></span><br><span class="line">        plt.xlabel(<span class="string">"Epochs"</span>)</span><br><span class="line">        plt.ylabel(<span class="string">"Rate"</span>)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<p>最后的正确率可以达到98。</p>
<h1 id="六、SVM建模攻击代码实现"><a href="#六、SVM建模攻击代码实现" class="headerlink" title="六、SVM建模攻击代码实现"></a>六、SVM建模攻击代码实现</h1><h3 id="数据收集实现：-1"><a href="#数据收集实现：-1" class="headerlink" title="数据收集实现："></a>数据收集实现：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shape</span><span class="params">(M)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> len(M), len(M[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">out1 = open(<span class="string">'testdatasetin.csv'</span>, <span class="string">'w'</span>)</span><br><span class="line">out2 = open(<span class="string">'testdatasetout.csv'</span>, <span class="string">'w'</span>)</span><br><span class="line">csv_writer1 = csv.writer(out1)</span><br><span class="line">csv_writer2 = csv.writer(out2)</span><br><span class="line">csv_file = csv.reader(open(<span class="string">'仿真Arbiter_PUF.csv'</span>, <span class="string">'r'</span>))</span><br><span class="line"></span><br><span class="line">PUFdelay_np = []</span><br><span class="line">PUFdelay = []</span><br><span class="line">delay1 = <span class="number">0</span></span><br><span class="line">delay2 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> csv_file:</span><br><span class="line">    PUFdelay.append(i)</span><br><span class="line"></span><br><span class="line">PUFdelay_np = np.array(PUFdelay, dtype=float)</span><br><span class="line"></span><br><span class="line">C_np = [([<span class="number">0</span>] * <span class="number">64</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]</span><br><span class="line">C_np_csv = []</span><br><span class="line">seed = <span class="string">"01"</span></span><br><span class="line">counter1 = <span class="number">0</span></span><br><span class="line">counter11 = <span class="number">0</span></span><br><span class="line"><span class="comment">#counter0 = 0</span></span><br><span class="line">counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> counter != <span class="number">12500</span>:</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">64</span>):</span><br><span class="line">		binary = random.choice(seed)</span><br><span class="line">		<span class="keyword">if</span> binary == <span class="string">"1"</span>:</span><br><span class="line">			delaymiddle = delay2</span><br><span class="line">			delay2 = delay1</span><br><span class="line">			delay1 = delaymiddle</span><br><span class="line">			delay1 += float(PUFdelay[<span class="number">1</span>][i])</span><br><span class="line">			delay2 += float(PUFdelay[<span class="number">2</span>][i])</span><br><span class="line">			C_np[<span class="number">0</span>][i] = <span class="number">0</span></span><br><span class="line">			C_np[<span class="number">3</span>][i] = <span class="number">0</span></span><br><span class="line">			counter1 += <span class="number">1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">1</span>][i] = <span class="number">1</span></span><br><span class="line">				C_np[<span class="number">2</span>][i] = <span class="number">-1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">1</span>][i] = <span class="number">-1</span></span><br><span class="line">				C_np[<span class="number">2</span>][i] = <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> binary == <span class="string">"0"</span>:</span><br><span class="line">			delay1 += float(PUFdelay[<span class="number">0</span>][i])</span><br><span class="line">			delay2 += float(PUFdelay[<span class="number">3</span>][i])</span><br><span class="line">			C_np[<span class="number">1</span>][i] = <span class="number">0</span></span><br><span class="line">			C_np[<span class="number">2</span>][i] = <span class="number">0</span></span><br><span class="line">			<span class="comment">#counter0 += 1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">0</span>][i] = <span class="number">-1</span></span><br><span class="line">				C_np[<span class="number">3</span>][i] = <span class="number">1</span></span><br><span class="line">			<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">				C_np[<span class="number">0</span>][i] = <span class="number">1</span></span><br><span class="line">				C_np[<span class="number">3</span>][i] = <span class="number">-1</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">64</span>):</span><br><span class="line">			C_np_csv.append(C_np[i][j])</span><br><span class="line">	csv_writer1.writerow(C_np_csv)</span><br><span class="line">	<span class="keyword">if</span> counter1 % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">if</span>(delay1 &gt; delay2):</span><br><span class="line">			csv_writer2.writerow(<span class="string">"1"</span>)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			row = [<span class="number">-1</span>]</span><br><span class="line">			csv_writer2.writerow(row)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">if</span>(delay1 &lt;= delay2):</span><br><span class="line">			csv_writer2.writerow(<span class="string">"1"</span>)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			row = [<span class="number">-1</span>]</span><br><span class="line">			csv_writer2.writerow(row)</span><br><span class="line">	counter1 = <span class="number">0</span></span><br><span class="line">	delay1 = <span class="number">0</span></span><br><span class="line">	delay2 = <span class="number">0</span></span><br><span class="line">	C_np_csv = []</span><br><span class="line">	counter += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="SVM建模攻击实现："><a href="#SVM建模攻击实现：" class="headerlink" title="SVM建模攻击实现："></a>SVM建模攻击实现：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment">#产生数据</span></span><br><span class="line">x_vals = np.loadtxt(open(<span class="string">r"testdatasetin.csv"</span>, <span class="string">"r"</span>), delimiter=<span class="string">","</span>, skiprows=<span class="number">0</span>)</span><br><span class="line">y_vals = np.loadtxt(open(<span class="string">r"testdatasetout.csv"</span>, <span class="string">"r"</span>), delimiter=<span class="string">","</span>, skiprows=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#划分数据为训练集和测试集</span></span><br><span class="line">train_indices = np.random.choice(len(x_vals), round(len(x_vals)*<span class="number">0.8</span>), replace=<span class="keyword">False</span>)</span><br><span class="line">test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))</span><br><span class="line">x_vals_train = x_vals[train_indices]</span><br><span class="line">x_vals_test = x_vals[test_indices]</span><br><span class="line">y_vals_train = y_vals[train_indices]</span><br><span class="line">y_vals_test = y_vals[test_indices]</span><br><span class="line"><span class="comment">#批训练中批的大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># 初始化feedin</span></span><br><span class="line">x_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">256</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建变量</span></span><br><span class="line">W = tf.Variable(tf.random_normal(shape=[<span class="number">256</span>, <span class="number">1</span>]))</span><br><span class="line">b = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 定义线性模型</span></span><br><span class="line">model_output = tf.matmul(x_data, W)+b</span><br><span class="line"><span class="comment"># Declare vector L2 'norm' function squared</span></span><br><span class="line">l2_norm = tf.reduce_sum(tf.square(W))</span><br><span class="line"><span class="comment">#软正则化参数</span></span><br><span class="line">alpha = tf.constant([<span class="number">0.02</span>])</span><br><span class="line"><span class="comment">#定义损失函数</span></span><br><span class="line">classification_term = tf.reduce_mean(tf.maximum(<span class="number">0.</span>, <span class="number">1.</span>-model_output*y_target))</span><br><span class="line">loss = classification_term+alpha*l2_norm</span><br><span class="line"><span class="comment"># classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(model_output, y_target))))</span></span><br><span class="line"><span class="comment"># loss = tf.add(classification_term, tf.multiply(alpha, l2_norm))</span></span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line">prediction = tf.sign(model_output)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(loss)</span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">loss_vec = []</span><br><span class="line">train_accuracy = []</span><br><span class="line">test_accuracy = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">    rand_index = np.random.choice(len(x_vals_train), size=batch_size)</span><br><span class="line">    rand_x = x_vals_train[rand_index]</span><br><span class="line">    rand_y = np.transpose([y_vals_train[rand_index]])</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    temp_loss = sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    loss_vec.append(temp_loss)</span><br><span class="line">    train_acc_temp = sess.run(accuracy, feed_dict=&#123;</span><br><span class="line">                              x_data: x_vals_train, y_target: np.transpose([y_vals_train])&#125;)</span><br><span class="line">    train_accuracy.append(train_acc_temp)</span><br><span class="line">    test_acc_temp = sess.run(accuracy, feed_dict=&#123;</span><br><span class="line">                             x_data: x_vals_test, y_target: np.transpose([y_vals_test])&#125;)</span><br><span class="line">    test_accuracy.append(test_acc_temp)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' W = '</span> +</span><br><span class="line">              str(sess.run(W)) + <span class="string">'b = '</span> + str(sess.run(b)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(test_acc_temp))  <span class="comment"># test_acc_temp</span></span><br><span class="line">plt.plot(loss_vec)</span><br><span class="line">plt.plot(train_accuracy)</span><br><span class="line">plt.plot(test_accuracy)</span><br><span class="line">plt.legend([<span class="string">'损失'</span>, <span class="string">'训练精确度'</span>, <span class="string">'测试精确度'</span>])</span><br><span class="line">plt.ylim(<span class="number">0.</span>, <span class="number">1.</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>最后的正确率会达到至少97.5%以上。</p>
<p>由于个人精力有限，不再分析tensorflow开源机器学习神器和内部算法实现。</p>
<p>​<br>​    </p>
<p>​<br>​<br>​    </p>
<p>​<br>​<br>​    </p>
</div></article></div></main><footer><div class="paginator"><a href="/2018/04/29/HTTPS配置/" class="prev">PREV</a><a href="/2018/04/19/SQL练习/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2018 <a href="http://yoursite.com">zhs</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>